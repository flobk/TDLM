{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from model import MD4Config, MD4\n",
    "# Device setup\n",
    "device = \"cuda:0\"\n",
    "print(f\"Using device: {device}\")\n",
    "# Enable TF32 for faster matrix multiplications on Ampere+ GPUs\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Text length: 68091636 characters\n",
      "Vocab size: 90\n"
     ]
    }
   ],
   "source": [
    "with open(\"blobs/wine_0.txt\", \"r\", encoding=\"utf-8\") as f0, \\\n",
    "     open(\"blobs/wine_1.txt\", \"r\", encoding=\"utf-8\") as f1, \\\n",
    "     open(\"blobs/wine_2.txt\", \"r\", encoding=\"utf-8\") as f2:\n",
    "    text = f0.read() + f1.read() + f2.read()\n",
    "\n",
    "# Create train / val tensor\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Total Text length: {len(text)} characters\")\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "def decode(ids):\n",
    "    return ''.join([itos[i] for i in ids if i < vocab_size])\n",
    "data_tensor = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.95 * len(data_tensor)) # 90/10 split\n",
    "train_data = data_tensor[:n]\n",
    "val_data = data_tensor[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/esx124-2243115/tmp/ipykernel_4186651/3900788819.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == torch.float16))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer using fused AdamW: True\n",
      "Number of model parameters: 40622080\n",
      "Starting training from scratch...\n",
      "--- Training Status ---\n",
      "Steps: 0 -> 50000\n",
      "Remaining steps: 50000\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "config = MD4Config(vocab_size)\n",
    "\n",
    "# Specify wether to train from scratch or resume from a checkpoint\n",
    "resume_from = None\n",
    "# resume_from = \"checkpoints/model_step_51976.pt\"\n",
    "# Specify the new max steps if resumed\n",
    "# if resume_from: config.max_steps = 55000 \n",
    "\n",
    "# Set model dtype \n",
    "dtype = torch.bfloat16\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == torch.float16))\n",
    "\n",
    "# Init model\n",
    "model = MD4(config)\n",
    "model.to(device)\n",
    "optimizer = model.configure_optimizers(weight_decay=1e-1, learning_rate=config.learning_rate, device_type=device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of model parameters: {num_params}\")\n",
    "\n",
    "start_step = 0\n",
    "if resume_from and os.path.exists(resume_from):\n",
    "    print(f\"Resuming training from {resume_from}...\")\n",
    "    checkpoint = torch.load(resume_from, map_location=device, weights_only=False)\n",
    "    # for compiled models\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k, v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_step = checkpoint['step']\n",
    "    print(f\"Successfully loaded. Resuming from step {start_step}\")\n",
    "else: print(\"Starting training from scratch...\")\n",
    "\n",
    "# Helpers\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup\n",
    "    if it < config.warmup_steps:\n",
    "        return config.learning_rate * (it + 1) / (config.warmup_steps + 1)\n",
    "    # 2) if it > max_steps, return min learning rate\n",
    "    if it > config.max_steps:\n",
    "        return config.min_lr\n",
    "    # 3) in between, use cosine decay\n",
    "    decay_ratio = (it - config.warmup_steps) / (config.max_steps - config.warmup_steps)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) \n",
    "    return config.min_lr + coeff * (config.learning_rate - config.min_lr)\n",
    "\n",
    "def get_batch(split, seqlen, batch_size):\n",
    "    d = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(d) - seqlen, (batch_size,))\n",
    "    X = torch.stack([d[i:i+seqlen] for i in ix])\n",
    "    return X.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(eval_iters=50):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X = get_batch(split, config.block_size, config.batch_size)\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=dtype):\n",
    "                loss = model.compute_loss(X)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "tokens_per_step = config.batch_size * config.block_size\n",
    "remaining_steps = config.max_steps - start_step\n",
    "total_tokens_trained = tokens_per_step * config.max_steps\n",
    "dataset_tokens = len(train_data)\n",
    "print(f\"--- Training Status ---\")\n",
    "print(f\"Steps: {start_step} -> {config.max_steps}\")\n",
    "print(f\"Remaining steps: {remaining_steps}\")\n",
    "print(f\"----------------------\")\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# COMPILATION\n",
    "model = torch.compile(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0845921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0 | Loss: 573.8300 | LR: 2.00e-07 | Speed: 2936859 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 588.0111 | Val Loss: 586.6883\n",
      "\n",
      "--- Generating ---\n",
      "JMzuC%\n",
      "bVTtKEzMG]vNdS,-*K%.RVF6j@Iff'TBBt79H]OABiKR24\n",
      " w*UnAEv\n",
      "Pj_)21J]NUx_`y:v5]CCE-loG#];QEN#:EacMB!DE4jTIs-Ha)FVp&$,\"M/\n",
      "------------------\n",
      "\n",
      "Step  100 | Loss: 419.4408 | LR: 2.02e-05 | Speed: 124621 tok/s\n",
      "Step  200 | Loss: 376.1278 | LR: 4.02e-05 | Speed: 244410 tok/s\n",
      "Step  300 | Loss: 342.3965 | LR: 6.01e-05 | Speed: 246025 tok/s\n",
      "Step  400 | Loss: 315.3194 | LR: 8.01e-05 | Speed: 246673 tok/s\n",
      "Step  500 | Loss: 292.5927 | LR: 1.00e-04 | Speed: 246432 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 272.7625 | Val Loss: 263.9272\n",
      "Step  600 | Loss: 252.7778 | LR: 1.20e-04 | Speed: 174401 tok/s\n",
      "Step  700 | Loss: 255.3970 | LR: 1.40e-04 | Speed: 243273 tok/s\n",
      "Step  800 | Loss: 236.7417 | LR: 1.60e-04 | Speed: 246787 tok/s\n",
      "Step  900 | Loss: 228.4727 | LR: 1.80e-04 | Speed: 244668 tok/s\n",
      "Step 1000 | Loss: 241.4666 | LR: 2.00e-04 | Speed: 249019 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 218.1567 | Val Loss: 215.5300\n",
      "\n",
      "--- Generating ---\n",
      "Aalike mase. Greabtones n to crs. It theass the wine rood aquectes drip, noted flavarrs. Therry nud sepper. Thes wine to swith i\n",
      "------------------\n",
      "\n",
      "Step 1100 | Loss: 219.1672 | LR: 2.00e-04 | Speed: 160628 tok/s\n",
      "Step 1200 | Loss: 205.2849 | LR: 2.00e-04 | Speed: 244605 tok/s\n",
      "Step 1300 | Loss: 219.1660 | LR: 2.00e-04 | Speed: 243573 tok/s\n",
      "Step 1400 | Loss: 204.7849 | LR: 2.00e-04 | Speed: 248890 tok/s\n",
      "Step 1500 | Loss: 200.9188 | LR: 2.00e-04 | Speed: 249538 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 198.0476 | Val Loss: 194.4892\n",
      "Step 1600 | Loss: 202.3771 | LR: 2.00e-04 | Speed: 173235 tok/s\n",
      "Step 1700 | Loss: 198.6931 | LR: 2.00e-04 | Speed: 248303 tok/s\n",
      "Step 1800 | Loss: 208.3673 | LR: 2.00e-04 | Speed: 248604 tok/s\n",
      "Step 1900 | Loss: 195.2348 | LR: 2.00e-04 | Speed: 246889 tok/s\n",
      "Step 2000 | Loss: 210.5221 | LR: 2.00e-04 | Speed: 249385 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 184.9197 | Val Loss: 183.1936\n",
      "\n",
      "--- Generating ---\n",
      "how compelbers geen a finithes one, but the nose supeled wine, with as  leftly spited tompactive. Flaorkeak, hus alos is mediral\n",
      "------------------\n",
      "\n",
      "Step 2100 | Loss: 182.4405 | LR: 2.00e-04 | Speed: 165077 tok/s\n",
      "Step 2200 | Loss: 194.1391 | LR: 2.00e-04 | Speed: 244463 tok/s\n",
      "Step 2300 | Loss: 199.2443 | LR: 2.00e-04 | Speed: 250218 tok/s\n",
      "Step 2400 | Loss: 193.9706 | LR: 2.00e-04 | Speed: 246501 tok/s\n",
      "Step 2500 | Loss: 185.8752 | LR: 2.00e-04 | Speed: 247526 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 180.8948 | Val Loss: 178.6281\n",
      "Step 2600 | Loss: 174.8886 | LR: 2.00e-04 | Speed: 175958 tok/s\n",
      "Step 2700 | Loss: 191.1576 | LR: 1.99e-04 | Speed: 246227 tok/s\n",
      "Step 2800 | Loss: 190.0797 | LR: 1.99e-04 | Speed: 250894 tok/s\n",
      "Step 2900 | Loss: 177.4681 | LR: 1.99e-04 | Speed: 246889 tok/s\n",
      "Step 3000 | Loss: 185.1230 | LR: 1.99e-04 | Speed: 247127 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 173.4872 | Val Loss: 173.4990\n",
      "\n",
      "--- Generating ---\n",
      " blueberriet black-bodied by colate, and balinc hishireviting a be not of stage green cugar wherry on lfvors of raspeday, comble\n",
      "------------------\n",
      "\n",
      "Step 3100 | Loss: 172.7692 | LR: 1.99e-04 | Speed: 165041 tok/s\n",
      "Step 3200 | Loss: 181.5436 | LR: 1.99e-04 | Speed: 248744 tok/s\n",
      "Step 3300 | Loss: 185.8918 | LR: 1.99e-04 | Speed: 245730 tok/s\n",
      "Step 3400 | Loss: 191.6082 | LR: 1.99e-04 | Speed: 244946 tok/s\n",
      "Step 3500 | Loss: 184.3943 | LR: 1.99e-04 | Speed: 247523 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 170.7049 | Val Loss: 167.3943\n",
      "Step 3600 | Loss: 178.1699 | LR: 1.99e-04 | Speed: 174354 tok/s\n",
      "Step 3700 | Loss: 178.5200 | LR: 1.99e-04 | Speed: 247683 tok/s\n",
      "Step 3800 | Loss: 159.2408 | LR: 1.98e-04 | Speed: 250076 tok/s\n",
      "Step 3900 | Loss: 180.2255 | LR: 1.98e-04 | Speed: 250288 tok/s\n",
      "Step 4000 | Loss: 164.5697 | LR: 1.98e-04 | Speed: 250135 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 165.9553 | Val Loss: 166.0733\n",
      "\n",
      "--- Generating ---\n",
      "s a quiliabe but remidgenalline jaymunts porgent, rich, ainical flavors. Noir and tart, supering thes shep halp tfd intense, sch\n",
      "------------------\n",
      "\n",
      "Step 4100 | Loss: 165.1760 | LR: 1.98e-04 | Speed: 164318 tok/s\n",
      "Step 4200 | Loss: 161.3548 | LR: 1.98e-04 | Speed: 247823 tok/s\n",
      "Step 4300 | Loss: 203.0803 | LR: 1.98e-04 | Speed: 248376 tok/s\n",
      "Step 4400 | Loss: 180.3336 | LR: 1.98e-04 | Speed: 251999 tok/s\n",
      "Step 4500 | Loss: 156.3503 | LR: 1.98e-04 | Speed: 243206 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 165.8914 | Val Loss: 162.0345\n",
      "Step 4600 | Loss: 167.0564 | LR: 1.97e-04 | Speed: 173984 tok/s\n",
      "Step 4700 | Loss: 178.3140 | LR: 1.97e-04 | Speed: 243107 tok/s\n",
      "Step 4800 | Loss: 163.7535 | LR: 1.97e-04 | Speed: 240076 tok/s\n",
      "Step 4900 | Loss: 168.8964 | LR: 1.97e-04 | Speed: 243264 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_5000.pt\n",
      "Step 5000 | Loss: 178.1981 | LR: 1.97e-04 | Speed: 219862 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 165.8289 | Val Loss: 161.1052\n",
      "\n",
      "--- Generating ---\n",
      "funt. It's a nicely saida touchool, wheffy of caramel cassiscree Crespberries, viluetic blend tart, this  lend to westain good b\n",
      "------------------\n",
      "\n",
      "Step 5100 | Loss: 168.3662 | LR: 1.97e-04 | Speed: 158817 tok/s\n",
      "Step 5200 | Loss: 151.6732 | LR: 1.97e-04 | Speed: 246148 tok/s\n",
      "Step 5300 | Loss: 168.1715 | LR: 1.96e-04 | Speed: 244292 tok/s\n",
      "Step 5400 | Loss: 162.7155 | LR: 1.96e-04 | Speed: 245803 tok/s\n",
      "Step 5500 | Loss: 168.2736 | LR: 1.96e-04 | Speed: 243123 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 163.1611 | Val Loss: 156.2751\n",
      "Step 5600 | Loss: 154.8462 | LR: 1.96e-04 | Speed: 169483 tok/s\n",
      "Step 5700 | Loss: 158.2026 | LR: 1.96e-04 | Speed: 238801 tok/s\n",
      "Step 5800 | Loss: 162.0549 | LR: 1.96e-04 | Speed: 248565 tok/s\n",
      "Step 5900 | Loss: 173.6772 | LR: 1.95e-04 | Speed: 237395 tok/s\n",
      "Step 6000 | Loss: 184.0100 | LR: 1.95e-04 | Speed: 248767 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 159.3107 | Val Loss: 156.0310\n",
      "\n",
      "--- Generating ---\n",
      "l of the wenter rivers ab grapefruits that's fruity and frighings of raspefruit to seem for this ne ly potented in a fiort here,\n",
      "------------------\n",
      "\n",
      "Step 6100 | Loss: 158.1647 | LR: 1.95e-04 | Speed: 162357 tok/s\n",
      "Step 6200 | Loss: 169.5572 | LR: 1.95e-04 | Speed: 245994 tok/s\n",
      "Step 6300 | Loss: 160.0172 | LR: 1.95e-04 | Speed: 237506 tok/s\n",
      "Step 6400 | Loss: 157.1159 | LR: 1.94e-04 | Speed: 246368 tok/s\n",
      "Step 6500 | Loss: 169.5435 | LR: 1.94e-04 | Speed: 244383 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 157.4830 | Val Loss: 155.5486\n",
      "Step 6600 | Loss: 148.6702 | LR: 1.94e-04 | Speed: 170147 tok/s\n",
      "Step 6700 | Loss: 179.3929 | LR: 1.94e-04 | Speed: 243890 tok/s\n",
      "Step 6800 | Loss: 155.8307 | LR: 1.94e-04 | Speed: 247064 tok/s\n",
      "Step 6900 | Loss: 167.3130 | LR: 1.93e-04 | Speed: 242347 tok/s\n",
      "Step 7000 | Loss: 168.5811 | LR: 1.93e-04 | Speed: 241779 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 156.0296 | Val Loss: 153.1067\n",
      "\n",
      "--- Generating ---\n",
      " at B.d, with a f Sunky, chuenced and mupresifts every hine is rustic disport by or absctuated  by new Solliowith, a pelse past \n",
      "------------------\n",
      "\n",
      "Step 7100 | Loss: 150.4913 | LR: 1.93e-04 | Speed: 158149 tok/s\n",
      "Step 7200 | Loss: 160.5481 | LR: 1.93e-04 | Speed: 244384 tok/s\n",
      "Step 7300 | Loss: 165.8909 | LR: 1.92e-04 | Speed: 244670 tok/s\n",
      "Step 7400 | Loss: 174.0205 | LR: 1.92e-04 | Speed: 244227 tok/s\n",
      "Step 7500 | Loss: 171.8108 | LR: 1.92e-04 | Speed: 240297 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 154.6642 | Val Loss: 152.8177\n",
      "Step 7600 | Loss: 165.6182 | LR: 1.92e-04 | Speed: 173017 tok/s\n",
      "Step 7700 | Loss: 161.8485 | LR: 1.91e-04 | Speed: 240013 tok/s\n",
      "Step 7800 | Loss: 168.5023 | LR: 1.91e-04 | Speed: 239372 tok/s\n",
      "Step 7900 | Loss: 149.7999 | LR: 1.91e-04 | Speed: 241071 tok/s\n",
      "Step 8000 | Loss: 167.8975 | LR: 1.91e-04 | Speed: 248548 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 153.9978 | Val Loss: 151.6332\n",
      "\n",
      "--- Generating ---\n",
      "ch malablack struazed with acidity aromas of coctacize jam-aced tak not,s of a soft. Bright, good with burtery plump and cherry \n",
      "------------------\n",
      "\n",
      "Step 8100 | Loss: 151.2366 | LR: 1.90e-04 | Speed: 158434 tok/s\n",
      "Step 8200 | Loss: 154.5914 | LR: 1.90e-04 | Speed: 243905 tok/s\n",
      "Step 8300 | Loss: 165.3219 | LR: 1.90e-04 | Speed: 239390 tok/s\n",
      "Step 8400 | Loss: 151.5781 | LR: 1.90e-04 | Speed: 243192 tok/s\n",
      "Step 8500 | Loss: 153.9664 | LR: 1.89e-04 | Speed: 246421 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 154.0549 | Val Loss: 149.7229\n",
      "Step 8600 | Loss: 147.1493 | LR: 1.89e-04 | Speed: 168736 tok/s\n",
      "Step 8700 | Loss: 163.9300 | LR: 1.89e-04 | Speed: 242618 tok/s\n",
      "Step 8800 | Loss: 155.2401 | LR: 1.88e-04 | Speed: 241366 tok/s\n",
      "Step 8900 | Loss: 160.5860 | LR: 1.88e-04 | Speed: 245974 tok/s\n",
      "Step 9000 | Loss: 170.7929 | LR: 1.88e-04 | Speed: 244909 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 149.9968 | Val Loss: 149.5378\n",
      "\n",
      "--- Generating ---\n",
      "ormuch in itm zeal forward lad the pramise putstyctics, the Vineyard, sweet respherey flavors, in a light laye for enoompilling \n",
      "------------------\n",
      "\n",
      "Step 9100 | Loss: 162.7315 | LR: 1.87e-04 | Speed: 157956 tok/s\n",
      "Step 9200 | Loss: 153.5432 | LR: 1.87e-04 | Speed: 241016 tok/s\n",
      "Step 9300 | Loss: 165.1114 | LR: 1.87e-04 | Speed: 242973 tok/s\n",
      "Step 9400 | Loss: 163.7941 | LR: 1.87e-04 | Speed: 247477 tok/s\n",
      "Step 9500 | Loss: 150.1916 | LR: 1.86e-04 | Speed: 243140 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 150.8071 | Val Loss: 148.9970\n",
      "Step 9600 | Loss: 143.9737 | LR: 1.86e-04 | Speed: 172943 tok/s\n",
      "Step 9700 | Loss: 151.5723 | LR: 1.86e-04 | Speed: 240120 tok/s\n",
      "Step 9800 | Loss: 154.4676 | LR: 1.85e-04 | Speed: 246051 tok/s\n",
      "Step 9900 | Loss: 161.4753 | LR: 1.85e-04 | Speed: 243631 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_10000.pt\n",
      "Step 10000 | Loss: 181.0060 | LR: 1.85e-04 | Speed: 224771 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 149.1000 | Val Loss: 147.2474\n",
      "\n",
      "--- Generating ---\n",
      " tasted with dried cinnamon and spicegr. Tace; it's full, strough tmouthfeel. Darky fruity, an modium textuse, it is a dense, wi\n",
      "------------------\n",
      "\n",
      "Step 10100 | Loss: 144.5703 | LR: 1.84e-04 | Speed: 162301 tok/s\n",
      "Step 10200 | Loss: 159.5965 | LR: 1.84e-04 | Speed: 242832 tok/s\n",
      "Step 10300 | Loss: 152.0822 | LR: 1.84e-04 | Speed: 245636 tok/s\n",
      "Step 10400 | Loss: 159.9164 | LR: 1.83e-04 | Speed: 245025 tok/s\n",
      "Step 10500 | Loss: 147.4868 | LR: 1.83e-04 | Speed: 238158 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 149.2736 | Val Loss: 145.9660\n",
      "Step 10600 | Loss: 163.3495 | LR: 1.83e-04 | Speed: 170370 tok/s\n",
      "Step 10700 | Loss: 140.7619 | LR: 1.82e-04 | Speed: 242719 tok/s\n",
      "Step 10800 | Loss: 156.3312 | LR: 1.82e-04 | Speed: 241887 tok/s\n",
      "Step 10900 | Loss: 141.2469 | LR: 1.81e-04 | Speed: 245128 tok/s\n",
      "Step 11000 | Loss: 158.0551 | LR: 1.81e-04 | Speed: 241922 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 147.6387 | Val Loss: 146.2270\n",
      "\n",
      "--- Generating ---\n",
      "aspberry aromas aromas peetrumely currat cherry and berries. The round and south, with shamed in a little pair of new oak Cullry\n",
      "------------------\n",
      "\n",
      "Step 11100 | Loss: 155.9836 | LR: 1.81e-04 | Speed: 158509 tok/s\n",
      "Step 11200 | Loss: 155.9235 | LR: 1.80e-04 | Speed: 240230 tok/s\n",
      "Step 11300 | Loss: 157.7432 | LR: 1.80e-04 | Speed: 248067 tok/s\n",
      "Step 11400 | Loss: 139.4576 | LR: 1.80e-04 | Speed: 244871 tok/s\n",
      "Step 11500 | Loss: 156.4578 | LR: 1.79e-04 | Speed: 244335 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 146.6563 | Val Loss: 146.2411\n",
      "Step 11600 | Loss: 150.6731 | LR: 1.79e-04 | Speed: 172852 tok/s\n",
      "Step 11700 | Loss: 154.8367 | LR: 1.79e-04 | Speed: 245278 tok/s\n",
      "Step 11800 | Loss: 154.5202 | LR: 1.78e-04 | Speed: 243616 tok/s\n",
      "Step 11900 | Loss: 139.5616 | LR: 1.78e-04 | Speed: 244832 tok/s\n",
      "Step 12000 | Loss: 151.6181 | LR: 1.77e-04 | Speed: 242076 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 146.8831 | Val Loss: 144.7734\n",
      "\n",
      "--- Generating ---\n",
      "y pit with a pipe rose fresh braci, corn roll. It nends you millow on this palate, smells with apple and handlarine quadity, thi\n",
      "------------------\n",
      "\n",
      "Step 12100 | Loss: 141.2482 | LR: 1.77e-04 | Speed: 161919 tok/s\n",
      "Step 12200 | Loss: 162.6344 | LR: 1.77e-04 | Speed: 242043 tok/s\n",
      "Step 12300 | Loss: 159.7279 | LR: 1.76e-04 | Speed: 241964 tok/s\n",
      "Step 12400 | Loss: 155.1182 | LR: 1.76e-04 | Speed: 245791 tok/s\n",
      "Step 12500 | Loss: 154.0354 | LR: 1.75e-04 | Speed: 242006 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 146.2170 | Val Loss: 143.7326\n",
      "Step 12600 | Loss: 155.1355 | LR: 1.75e-04 | Speed: 171869 tok/s\n",
      "Step 12700 | Loss: 168.2860 | LR: 1.75e-04 | Speed: 245312 tok/s\n",
      "Step 12800 | Loss: 149.1302 | LR: 1.74e-04 | Speed: 240462 tok/s\n",
      "Step 12900 | Loss: 149.7977 | LR: 1.74e-04 | Speed: 240251 tok/s\n",
      "Step 13000 | Loss: 177.7442 | LR: 1.73e-04 | Speed: 243388 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 145.3969 | Val Loss: 142.5848\n",
      "\n",
      "--- Generating ---\n",
      "rds of aromas of currant, raisi and fruit, salty full of dried fildflowerful and dar wood. The mouth, this woody end every wine \n",
      "------------------\n",
      "\n",
      "Step 13100 | Loss: 153.5563 | LR: 1.73e-04 | Speed: 156985 tok/s\n",
      "Step 13200 | Loss: 143.6940 | LR: 1.72e-04 | Speed: 241689 tok/s\n",
      "Step 13300 | Loss: 147.6611 | LR: 1.72e-04 | Speed: 245173 tok/s\n",
      "Step 13400 | Loss: 156.6570 | LR: 1.72e-04 | Speed: 248666 tok/s\n",
      "Step 13500 | Loss: 151.1993 | LR: 1.71e-04 | Speed: 244834 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 146.9178 | Val Loss: 141.8884\n",
      "Step 13600 | Loss: 146.0056 | LR: 1.71e-04 | Speed: 171373 tok/s\n",
      "Step 13700 | Loss: 135.9883 | LR: 1.70e-04 | Speed: 247828 tok/s\n",
      "Step 13800 | Loss: 151.9114 | LR: 1.70e-04 | Speed: 241567 tok/s\n",
      "Step 13900 | Loss: 143.0665 | LR: 1.69e-04 | Speed: 241715 tok/s\n",
      "Step 14000 | Loss: 142.2703 | LR: 1.69e-04 | Speed: 241930 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 144.8962 | Val Loss: 142.3934\n",
      "\n",
      "--- Generating ---\n",
      "Do to Red vineyard spice flavors hdge freshness. Cdeep and millicg. Heavy Neir tartey, this is very quanting deiurilend and the \n",
      "------------------\n",
      "\n",
      "Step 14100 | Loss: 147.1807 | LR: 1.68e-04 | Speed: 157465 tok/s\n",
      "Step 14200 | Loss: 156.2886 | LR: 1.68e-04 | Speed: 240991 tok/s\n",
      "Step 14300 | Loss: 158.1877 | LR: 1.68e-04 | Speed: 242790 tok/s\n",
      "Step 14400 | Loss: 139.4493 | LR: 1.67e-04 | Speed: 241815 tok/s\n",
      "Step 14500 | Loss: 158.1904 | LR: 1.67e-04 | Speed: 243735 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 141.8258 | Val Loss: 140.3457\n",
      "Step 14600 | Loss: 151.5554 | LR: 1.66e-04 | Speed: 172831 tok/s\n",
      "Step 14700 | Loss: 145.3522 | LR: 1.66e-04 | Speed: 243017 tok/s\n",
      "Step 14800 | Loss: 148.3207 | LR: 1.65e-04 | Speed: 243416 tok/s\n",
      "Step 14900 | Loss: 145.6993 | LR: 1.65e-04 | Speed: 246257 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_15000.pt\n",
      "Step 15000 | Loss: 150.6979 | LR: 1.64e-04 | Speed: 219807 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 141.7416 | Val Loss: 140.7658\n",
      "\n",
      "--- Generating ---\n",
      " oef with whotes rhach in or more high meal. Loody and fresh for an weightly high word, delicate wine cherry certain y juicy and\n",
      "------------------\n",
      "\n",
      "Step 15100 | Loss: 161.3675 | LR: 1.64e-04 | Speed: 163119 tok/s\n",
      "Step 15200 | Loss: 153.3691 | LR: 1.63e-04 | Speed: 241257 tok/s\n",
      "Step 15300 | Loss: 138.2468 | LR: 1.63e-04 | Speed: 249415 tok/s\n",
      "Step 15400 | Loss: 146.9118 | LR: 1.62e-04 | Speed: 244918 tok/s\n",
      "Step 15500 | Loss: 147.1520 | LR: 1.62e-04 | Speed: 241768 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 142.4849 | Val Loss: 141.2146\n",
      "Step 15600 | Loss: 141.8532 | LR: 1.61e-04 | Speed: 168684 tok/s\n",
      "Step 15700 | Loss: 155.4265 | LR: 1.61e-04 | Speed: 242370 tok/s\n",
      "Step 15800 | Loss: 143.5938 | LR: 1.60e-04 | Speed: 246453 tok/s\n",
      "Step 15900 | Loss: 130.3838 | LR: 1.60e-04 | Speed: 237015 tok/s\n",
      "Step 16000 | Loss: 154.3995 | LR: 1.59e-04 | Speed: 241951 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 140.2136 | Val Loss: 141.3495\n",
      "\n",
      "--- Generating ---\n",
      "te for oak to the mouth, with biantic basics in the acidity. Some wine to pushes a soft delicate  Impressive from its cherr and,\n",
      "------------------\n",
      "\n",
      "Step 16100 | Loss: 141.6954 | LR: 1.59e-04 | Speed: 160222 tok/s\n",
      "Step 16200 | Loss: 146.4444 | LR: 1.58e-04 | Speed: 239045 tok/s\n",
      "Step 16300 | Loss: 161.2882 | LR: 1.58e-04 | Speed: 247952 tok/s\n",
      "Step 16400 | Loss: 148.8816 | LR: 1.57e-04 | Speed: 241495 tok/s\n",
      "Step 16500 | Loss: 134.4248 | LR: 1.57e-04 | Speed: 237251 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 141.9097 | Val Loss: 140.3311\n",
      "Step 16600 | Loss: 145.4724 | LR: 1.56e-04 | Speed: 171683 tok/s\n",
      "Step 16700 | Loss: 135.3777 | LR: 1.56e-04 | Speed: 241660 tok/s\n",
      "Step 16800 | Loss: 142.2721 | LR: 1.55e-04 | Speed: 242388 tok/s\n",
      "Step 16900 | Loss: 117.5171 | LR: 1.55e-04 | Speed: 243622 tok/s\n",
      "Step 17000 | Loss: 141.8756 | LR: 1.54e-04 | Speed: 245150 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 144.1904 | Val Loss: 138.1445\n",
      "\n",
      "--- Generating ---\n",
      "late shows a very top of Coarvesce, with nearow berry and charry notes and tannins, making an Emegacite that namestant to creat \n",
      "------------------\n",
      "\n",
      "Step 17100 | Loss: 139.6376 | LR: 1.54e-04 | Speed: 161009 tok/s\n",
      "Step 17200 | Loss: 153.0780 | LR: 1.53e-04 | Speed: 249211 tok/s\n",
      "Step 17300 | Loss: 136.6455 | LR: 1.53e-04 | Speed: 240763 tok/s\n",
      "Step 17400 | Loss: 141.4380 | LR: 1.52e-04 | Speed: 244976 tok/s\n",
      "Step 17500 | Loss: 144.7261 | LR: 1.52e-04 | Speed: 244836 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 141.2275 | Val Loss: 138.9585\n",
      "Step 17600 | Loss: 154.6986 | LR: 1.51e-04 | Speed: 172137 tok/s\n",
      "Step 17700 | Loss: 147.1708 | LR: 1.51e-04 | Speed: 241897 tok/s\n",
      "Step 17800 | Loss: 143.1524 | LR: 1.50e-04 | Speed: 244530 tok/s\n",
      "Step 17900 | Loss: 151.8739 | LR: 1.49e-04 | Speed: 242309 tok/s\n",
      "Step 18000 | Loss: 162.3943 | LR: 1.49e-04 | Speed: 238150 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 140.2458 | Val Loss: 137.5085\n",
      "\n",
      "--- Generating ---\n",
      "omplexity on the round--viving palate tank h les of cllam at forest and pepper baturigury aromas and good tannins, and the first\n",
      "------------------\n",
      "\n",
      "Step 18100 | Loss: 141.2458 | LR: 1.48e-04 | Speed: 156972 tok/s\n",
      "Step 18200 | Loss: 140.0911 | LR: 1.48e-04 | Speed: 243787 tok/s\n",
      "Step 18300 | Loss: 131.0175 | LR: 1.47e-04 | Speed: 245872 tok/s\n",
      "Step 18400 | Loss: 133.4499 | LR: 1.47e-04 | Speed: 239945 tok/s\n",
      "Step 18500 | Loss: 146.6146 | LR: 1.46e-04 | Speed: 239382 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 138.8941 | Val Loss: 135.4912\n",
      "Step 18600 | Loss: 138.1598 | LR: 1.46e-04 | Speed: 174381 tok/s\n",
      "Step 18700 | Loss: 150.0481 | LR: 1.45e-04 | Speed: 247982 tok/s\n",
      "Step 18800 | Loss: 145.4226 | LR: 1.45e-04 | Speed: 239168 tok/s\n",
      "Step 18900 | Loss: 152.3643 | LR: 1.44e-04 | Speed: 241776 tok/s\n",
      "Step 19000 | Loss: 139.0993 | LR: 1.43e-04 | Speed: 243171 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 138.6973 | Val Loss: 136.7850\n",
      "\n",
      "--- Generating ---\n",
      "rrints, mints and mineral melives. Inky and muchness are fill hade about with the wine ness light fein and slight eltments. This\n",
      "------------------\n",
      "\n",
      "Step 19100 | Loss: 160.8504 | LR: 1.43e-04 | Speed: 159513 tok/s\n",
      "Step 19200 | Loss: 146.7115 | LR: 1.42e-04 | Speed: 243210 tok/s\n",
      "Step 19300 | Loss: 146.7788 | LR: 1.42e-04 | Speed: 244974 tok/s\n",
      "Step 19400 | Loss: 127.0992 | LR: 1.41e-04 | Speed: 249240 tok/s\n",
      "Step 19500 | Loss: 144.6976 | LR: 1.41e-04 | Speed: 243000 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 138.2350 | Val Loss: 135.6332\n",
      "Step 19600 | Loss: 151.6298 | LR: 1.40e-04 | Speed: 172544 tok/s\n",
      "Step 19700 | Loss: 126.9261 | LR: 1.40e-04 | Speed: 238019 tok/s\n",
      "Step 19800 | Loss: 127.2254 | LR: 1.39e-04 | Speed: 248405 tok/s\n",
      "Step 19900 | Loss: 139.5258 | LR: 1.38e-04 | Speed: 240693 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_20000.pt\n",
      "Step 20000 | Loss: 148.5290 | LR: 1.38e-04 | Speed: 219576 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 139.7577 | Val Loss: 135.0484\n",
      "\n",
      "--- Generating ---\n",
      " one from draw Aglianic mild'alop finest, and the lasteerpartes. Solid Italy to git this on sheakines for breadsh, with exotic m\n",
      "------------------\n",
      "\n",
      "Step 20100 | Loss: 137.8708 | LR: 1.37e-04 | Speed: 160377 tok/s\n",
      "Step 20200 | Loss: 155.6909 | LR: 1.37e-04 | Speed: 244775 tok/s\n",
      "Step 20300 | Loss: 150.2412 | LR: 1.36e-04 | Speed: 247338 tok/s\n",
      "Step 20400 | Loss: 148.4992 | LR: 1.36e-04 | Speed: 239807 tok/s\n",
      "Step 20500 | Loss: 143.6832 | LR: 1.35e-04 | Speed: 242764 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 135.9641 | Val Loss: 134.9101\n",
      "Step 20600 | Loss: 163.6034 | LR: 1.34e-04 | Speed: 173204 tok/s\n",
      "Step 20700 | Loss: 140.5495 | LR: 1.34e-04 | Speed: 243830 tok/s\n",
      "Step 20800 | Loss: 143.4234 | LR: 1.33e-04 | Speed: 247631 tok/s\n",
      "Step 20900 | Loss: 130.1871 | LR: 1.33e-04 | Speed: 245119 tok/s\n",
      "Step 21000 | Loss: 142.9578 | LR: 1.32e-04 | Speed: 249993 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 137.8654 | Val Loss: 136.4343\n",
      "\n",
      "--- Generating ---\n",
      "efreshing warm, but not probably totated, but juicy tannins and orawberry hold nually foods becore seccessible of Alrer di Iunap\n",
      "------------------\n",
      "\n",
      "Step 21100 | Loss: 125.6825 | LR: 1.31e-04 | Speed: 159781 tok/s\n",
      "Step 21200 | Loss: 142.0657 | LR: 1.31e-04 | Speed: 241696 tok/s\n",
      "Step 21300 | Loss: 115.9140 | LR: 1.30e-04 | Speed: 239814 tok/s\n",
      "Step 21400 | Loss: 142.1728 | LR: 1.30e-04 | Speed: 243463 tok/s\n",
      "Step 21500 | Loss: 142.1926 | LR: 1.29e-04 | Speed: 246102 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 138.9714 | Val Loss: 137.3595\n",
      "Step 21600 | Loss: 146.9583 | LR: 1.29e-04 | Speed: 172053 tok/s\n",
      "Step 21700 | Loss: 126.4368 | LR: 1.28e-04 | Speed: 240825 tok/s\n",
      "Step 21800 | Loss: 141.7058 | LR: 1.27e-04 | Speed: 248959 tok/s\n",
      "Step 21900 | Loss: 144.9401 | LR: 1.27e-04 | Speed: 242921 tok/s\n",
      "Step 22000 | Loss: 125.2427 | LR: 1.26e-04 | Speed: 238053 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 134.6085 | Val Loss: 134.4031\n",
      "\n",
      "--- Generating ---\n",
      "asothe maanial structure of pear mix and cocerinnal. The round and dry, but wite a dist for vanillamentse enierling flat to jumb\n",
      "------------------\n",
      "\n",
      "Step 22100 | Loss: 149.6751 | LR: 1.26e-04 | Speed: 158747 tok/s\n",
      "Step 22200 | Loss: 152.3086 | LR: 1.25e-04 | Speed: 240470 tok/s\n",
      "Step 22300 | Loss: 129.0186 | LR: 1.24e-04 | Speed: 244483 tok/s\n",
      "Step 22400 | Loss: 145.1815 | LR: 1.24e-04 | Speed: 241702 tok/s\n",
      "Step 22500 | Loss: 151.6506 | LR: 1.23e-04 | Speed: 243453 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 136.9692 | Val Loss: 135.9310\n",
      "Step 22600 | Loss: 133.4512 | LR: 1.23e-04 | Speed: 173518 tok/s\n",
      "Step 22700 | Loss: 126.0783 | LR: 1.22e-04 | Speed: 245102 tok/s\n",
      "Step 22800 | Loss: 145.5887 | LR: 1.21e-04 | Speed: 243552 tok/s\n",
      "Step 22900 | Loss: 149.6739 | LR: 1.21e-04 | Speed: 240961 tok/s\n",
      "Step 23000 | Loss: 143.9587 | LR: 1.20e-04 | Speed: 241710 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 137.7511 | Val Loss: 134.1469\n",
      "\n",
      "--- Generating ---\n",
      "raped unusual, its vour spices finesse a specidic in hugh. The wine lot the exmelling wine in a Ruta Bain-Weit re,eChalest in fi\n",
      "------------------\n",
      "\n",
      "Step 23100 | Loss: 156.6767 | LR: 1.20e-04 | Speed: 157310 tok/s\n",
      "Step 23200 | Loss: 136.0585 | LR: 1.19e-04 | Speed: 247857 tok/s\n",
      "Step 23300 | Loss: 139.9811 | LR: 1.18e-04 | Speed: 242957 tok/s\n",
      "Step 23400 | Loss: 158.4449 | LR: 1.18e-04 | Speed: 238573 tok/s\n",
      "Step 23500 | Loss: 141.7103 | LR: 1.17e-04 | Speed: 247873 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 135.9169 | Val Loss: 133.0549\n",
      "Step 23600 | Loss: 125.7312 | LR: 1.17e-04 | Speed: 170991 tok/s\n",
      "Step 23700 | Loss: 137.8562 | LR: 1.16e-04 | Speed: 240850 tok/s\n",
      "Step 23800 | Loss: 130.3000 | LR: 1.15e-04 | Speed: 243068 tok/s\n",
      "Step 23900 | Loss: 129.2183 | LR: 1.15e-04 | Speed: 242633 tok/s\n",
      "Step 24000 | Loss: 135.5296 | LR: 1.14e-04 | Speed: 241467 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 138.0095 | Val Loss: 132.7811\n",
      "\n",
      "--- Generating ---\n",
      "ely essuring cassis, plums, blackberries and deficious it fades into full and acidity, cooling style showing taste. Nice richnes\n",
      "------------------\n",
      "\n",
      "Step 24100 | Loss: 131.7020 | LR: 1.14e-04 | Speed: 161942 tok/s\n",
      "Step 24200 | Loss: 122.3678 | LR: 1.13e-04 | Speed: 241089 tok/s\n",
      "Step 24300 | Loss: 145.6253 | LR: 1.12e-04 | Speed: 247979 tok/s\n",
      "Step 24400 | Loss: 154.2450 | LR: 1.12e-04 | Speed: 241562 tok/s\n",
      "Step 24500 | Loss: 133.3417 | LR: 1.11e-04 | Speed: 244265 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 134.0417 | Val Loss: 132.0753\n",
      "Step 24600 | Loss: 134.1392 | LR: 1.10e-04 | Speed: 168469 tok/s\n",
      "Step 24700 | Loss: 152.7801 | LR: 1.10e-04 | Speed: 244332 tok/s\n",
      "Step 24800 | Loss: 130.1406 | LR: 1.09e-04 | Speed: 244100 tok/s\n",
      "Step 24900 | Loss: 131.8465 | LR: 1.09e-04 | Speed: 236323 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_25000.pt\n",
      "Step 25000 | Loss: 138.8533 | LR: 1.08e-04 | Speed: 222626 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 134.2597 | Val Loss: 131.9637\n",
      "\n",
      "--- Generating ---\n",
      "as structured, dry Merlot flavors that have  loariate minicial expressional pleasisted grounds on the wine. Full bodied and full\n",
      "------------------\n",
      "\n",
      "Step 25100 | Loss: 135.6437 | LR: 1.07e-04 | Speed: 163521 tok/s\n",
      "Step 25200 | Loss: 150.6013 | LR: 1.07e-04 | Speed: 246564 tok/s\n",
      "Step 25300 | Loss: 146.3222 | LR: 1.06e-04 | Speed: 244202 tok/s\n",
      "Step 25400 | Loss: 145.7050 | LR: 1.06e-04 | Speed: 238916 tok/s\n",
      "Step 25500 | Loss: 137.4874 | LR: 1.05e-04 | Speed: 237071 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 134.1727 | Val Loss: 133.1482\n",
      "Step 25600 | Loss: 127.8361 | LR: 1.04e-04 | Speed: 170556 tok/s\n",
      "Step 25700 | Loss: 140.9845 | LR: 1.04e-04 | Speed: 242275 tok/s\n",
      "Step 25800 | Loss: 128.4060 | LR: 1.03e-04 | Speed: 243636 tok/s\n",
      "Step 25900 | Loss: 134.8963 | LR: 1.03e-04 | Speed: 247975 tok/s\n",
      "Step 26000 | Loss: 126.2357 | LR: 1.02e-04 | Speed: 239702 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.4810 | Val Loss: 132.7272\n",
      "\n",
      "--- Generating ---\n",
      "dry, but be drinking now; very 2019. Earty cedar and earthy citrus notes add above everge to crust in flowly. As well, fall arou\n",
      "------------------\n",
      "\n",
      "Step 26100 | Loss: 136.7140 | LR: 1.01e-04 | Speed: 159449 tok/s\n",
      "Step 26200 | Loss: 133.4193 | LR: 1.01e-04 | Speed: 243445 tok/s\n",
      "Step 26300 | Loss: 133.9863 | LR: 1.00e-04 | Speed: 239492 tok/s\n",
      "Step 26400 | Loss: 135.8192 | LR: 9.95e-05 | Speed: 241452 tok/s\n",
      "Step 26500 | Loss: 152.6504 | LR: 9.89e-05 | Speed: 242781 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.6912 | Val Loss: 131.6685\n",
      "Step 26600 | Loss: 123.7738 | LR: 9.83e-05 | Speed: 171577 tok/s\n",
      "Step 26700 | Loss: 144.6794 | LR: 9.77e-05 | Speed: 244766 tok/s\n",
      "Step 26800 | Loss: 135.5035 | LR: 9.71e-05 | Speed: 239882 tok/s\n",
      "Step 26900 | Loss: 136.5036 | LR: 9.65e-05 | Speed: 243798 tok/s\n",
      "Step 27000 | Loss: 125.4677 | LR: 9.59e-05 | Speed: 243348 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 134.5131 | Val Loss: 130.2582\n",
      "\n",
      "--- Generating ---\n",
      "acter. Fig, rone, spice and cherry herb the warm tang.nClumings fa of flesh in thas superripe  freshness. Drink wine it gents an\n",
      "------------------\n",
      "\n",
      "Step 27100 | Loss: 131.7119 | LR: 9.53e-05 | Speed: 157704 tok/s\n",
      "Step 27200 | Loss: 144.5106 | LR: 9.47e-05 | Speed: 244797 tok/s\n",
      "Step 27300 | Loss: 127.9782 | LR: 9.41e-05 | Speed: 246779 tok/s\n",
      "Step 27400 | Loss: 130.4306 | LR: 9.35e-05 | Speed: 245626 tok/s\n",
      "Step 27500 | Loss: 143.9956 | LR: 9.29e-05 | Speed: 248613 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 133.6090 | Val Loss: 129.7798\n",
      "Step 27600 | Loss: 146.2298 | LR: 9.22e-05 | Speed: 173128 tok/s\n",
      "Step 27700 | Loss: 132.2293 | LR: 9.16e-05 | Speed: 241278 tok/s\n",
      "Step 27800 | Loss: 135.2057 | LR: 9.10e-05 | Speed: 244704 tok/s\n",
      "Step 27900 | Loss: 133.1829 | LR: 9.04e-05 | Speed: 245760 tok/s\n",
      "Step 28000 | Loss: 147.0836 | LR: 8.98e-05 | Speed: 243247 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.3685 | Val Loss: 131.8292\n",
      "\n",
      "--- Generating ---\n",
      " char and blackberries and cocoa and cedar. The more is ripe, cork envemoned and steely with brish yallow well. his is some you\n",
      "------------------\n",
      "\n",
      "Step 28100 | Loss: 133.8405 | LR: 8.92e-05 | Speed: 158080 tok/s\n",
      "Step 28200 | Loss: 129.0467 | LR: 8.86e-05 | Speed: 243999 tok/s\n",
      "Step 28300 | Loss: 119.7810 | LR: 8.80e-05 | Speed: 245551 tok/s\n",
      "Step 28400 | Loss: 137.2742 | LR: 8.74e-05 | Speed: 248383 tok/s\n",
      "Step 28500 | Loss: 126.6489 | LR: 8.68e-05 | Speed: 242609 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.2394 | Val Loss: 130.5564\n",
      "Step 28600 | Loss: 133.7240 | LR: 8.62e-05 | Speed: 169705 tok/s\n",
      "Step 28700 | Loss: 141.0764 | LR: 8.56e-05 | Speed: 248338 tok/s\n",
      "Step 28800 | Loss: 136.5578 | LR: 8.50e-05 | Speed: 240012 tok/s\n",
      "Step 28900 | Loss: 136.5442 | LR: 8.45e-05 | Speed: 241246 tok/s\n",
      "Step 29000 | Loss: 141.6060 | LR: 8.39e-05 | Speed: 249203 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.0789 | Val Loss: 130.5409\n",
      "\n",
      "--- Generating ---\n",
      ", there's firm, cheery drap note as the finish is loadted with oak and cassis and wood. White wine to given its polished tannins\n",
      "------------------\n",
      "\n",
      "Step 29100 | Loss: 136.4928 | LR: 8.33e-05 | Speed: 157559 tok/s\n",
      "Step 29200 | Loss: 138.2431 | LR: 8.27e-05 | Speed: 245809 tok/s\n",
      "Step 29300 | Loss: 142.5357 | LR: 8.21e-05 | Speed: 244046 tok/s\n",
      "Step 29400 | Loss: 134.2573 | LR: 8.15e-05 | Speed: 244765 tok/s\n",
      "Step 29500 | Loss: 143.3040 | LR: 8.09e-05 | Speed: 240971 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 131.4643 | Val Loss: 130.5010\n",
      "Step 29600 | Loss: 123.1142 | LR: 8.03e-05 | Speed: 173821 tok/s\n",
      "Step 29700 | Loss: 139.4307 | LR: 7.97e-05 | Speed: 239409 tok/s\n",
      "Step 29800 | Loss: 136.7755 | LR: 7.91e-05 | Speed: 244715 tok/s\n",
      "Step 29900 | Loss: 141.4940 | LR: 7.86e-05 | Speed: 242290 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_30000.pt\n",
      "Step 30000 | Loss: 148.6376 | LR: 7.80e-05 | Speed: 223308 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.2068 | Val Loss: 128.3769\n",
      "\n",
      "--- Generating ---\n",
      "gue to help iespite the find of this big Barrel aroma  fans. Notes of exotic plum and ground spice into matere verring to the mo\n",
      "------------------\n",
      "\n",
      "Step 30100 | Loss: 146.4500 | LR: 7.74e-05 | Speed: 159933 tok/s\n",
      "Step 30200 | Loss: 138.8349 | LR: 7.68e-05 | Speed: 245828 tok/s\n",
      "Step 30300 | Loss: 147.0666 | LR: 7.62e-05 | Speed: 243629 tok/s\n",
      "Step 30400 | Loss: 128.6405 | LR: 7.56e-05 | Speed: 246539 tok/s\n",
      "Step 30500 | Loss: 131.1201 | LR: 7.51e-05 | Speed: 241907 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.3009 | Val Loss: 131.1985\n",
      "Step 30600 | Loss: 134.1769 | LR: 7.45e-05 | Speed: 171329 tok/s\n",
      "Step 30700 | Loss: 148.6008 | LR: 7.39e-05 | Speed: 245633 tok/s\n",
      "Step 30800 | Loss: 140.6323 | LR: 7.33e-05 | Speed: 246668 tok/s\n",
      "Step 30900 | Loss: 119.4686 | LR: 7.28e-05 | Speed: 245285 tok/s\n",
      "Step 31000 | Loss: 129.2589 | LR: 7.22e-05 | Speed: 245255 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.0293 | Val Loss: 130.3408\n",
      "\n",
      "--- Generating ---\n",
      "ravel garven  in completel, with nutting spicies, mocha andal tropical fruits. This slightly ripe wine is rich, with and drink a\n",
      "------------------\n",
      "\n",
      "Step 31100 | Loss: 140.0475 | LR: 7.16e-05 | Speed: 160140 tok/s\n",
      "Step 31200 | Loss: 148.8403 | LR: 7.10e-05 | Speed: 245576 tok/s\n",
      "Step 31300 | Loss: 154.6796 | LR: 7.05e-05 | Speed: 239802 tok/s\n",
      "Step 31400 | Loss: 146.4981 | LR: 6.99e-05 | Speed: 240323 tok/s\n",
      "Step 31500 | Loss: 145.0705 | LR: 6.93e-05 | Speed: 247142 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 131.2065 | Val Loss: 130.1087\n",
      "Step 31600 | Loss: 117.9165 | LR: 6.88e-05 | Speed: 170419 tok/s\n",
      "Step 31700 | Loss: 135.7852 | LR: 6.82e-05 | Speed: 242711 tok/s\n",
      "Step 31800 | Loss: 126.2570 | LR: 6.77e-05 | Speed: 248486 tok/s\n",
      "Step 31900 | Loss: 131.6714 | LR: 6.71e-05 | Speed: 244359 tok/s\n",
      "Step 32000 | Loss: 121.1361 | LR: 6.65e-05 | Speed: 239188 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.7070 | Val Loss: 127.7975\n",
      "\n",
      "--- Generating ---\n",
      " flavors, with leather rind, who  loogteven is the nose overall more a aromatic of staying. Pretty beef oak, wood, Marusshey and\n",
      "------------------\n",
      "\n",
      "Step 32100 | Loss: 137.8937 | LR: 6.60e-05 | Speed: 159862 tok/s\n",
      "Step 32200 | Loss: 144.0920 | LR: 6.54e-05 | Speed: 238460 tok/s\n",
      "Step 32300 | Loss: 146.0122 | LR: 6.49e-05 | Speed: 248763 tok/s\n",
      "Step 32400 | Loss: 130.3027 | LR: 6.43e-05 | Speed: 242702 tok/s\n",
      "Step 32500 | Loss: 164.7756 | LR: 6.38e-05 | Speed: 239389 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 130.9982 | Val Loss: 127.4032\n",
      "Step 32600 | Loss: 154.6127 | LR: 6.32e-05 | Speed: 171439 tok/s\n",
      "Step 32700 | Loss: 124.4372 | LR: 6.27e-05 | Speed: 246562 tok/s\n",
      "Step 32800 | Loss: 135.9939 | LR: 6.21e-05 | Speed: 239988 tok/s\n",
      "Step 32900 | Loss: 138.0734 | LR: 6.16e-05 | Speed: 241372 tok/s\n",
      "Step 33000 | Loss: 135.4648 | LR: 6.11e-05 | Speed: 240466 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.9062 | Val Loss: 130.4490\n",
      "\n",
      "--- Generating ---\n",
      "aromas in  without enoigh. Made andays blendet from 60% (orenache (G:) end. It firms  with layer tannins. With mineral-custard t\n",
      "------------------\n",
      "\n",
      "Step 33100 | Loss: 130.5697 | LR: 6.05e-05 | Speed: 156237 tok/s\n",
      "Step 33200 | Loss: 135.7905 | LR: 6.00e-05 | Speed: 249024 tok/s\n",
      "Step 33300 | Loss: 144.6318 | LR: 5.94e-05 | Speed: 244949 tok/s\n",
      "Step 33400 | Loss: 134.5747 | LR: 5.89e-05 | Speed: 243406 tok/s\n",
      "Step 33500 | Loss: 133.2610 | LR: 5.84e-05 | Speed: 241465 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 130.2883 | Val Loss: 128.6407\n",
      "Step 33600 | Loss: 121.8983 | LR: 5.79e-05 | Speed: 170416 tok/s\n",
      "Step 33700 | Loss: 137.0487 | LR: 5.73e-05 | Speed: 239482 tok/s\n",
      "Step 33800 | Loss: 131.6151 | LR: 5.68e-05 | Speed: 243433 tok/s\n",
      "Step 33900 | Loss: 140.7444 | LR: 5.63e-05 | Speed: 244655 tok/s\n",
      "Step 34000 | Loss: 132.9992 | LR: 5.58e-05 | Speed: 246557 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 132.1762 | Val Loss: 127.0357\n",
      "\n",
      "--- Generating ---\n",
      ", hard notes of dark plum cola, herbs and leather. It balls spice presents more heft and accents. This wine is ripe all dry, tan\n",
      "------------------\n",
      "\n",
      "Step 34100 | Loss: 131.8673 | LR: 5.52e-05 | Speed: 159856 tok/s\n",
      "Step 34200 | Loss: 134.4882 | LR: 5.47e-05 | Speed: 242615 tok/s\n",
      "Step 34300 | Loss: 150.3963 | LR: 5.42e-05 | Speed: 244543 tok/s\n",
      "Step 34400 | Loss: 133.2024 | LR: 5.37e-05 | Speed: 240182 tok/s\n",
      "Step 34500 | Loss: 134.6881 | LR: 5.32e-05 | Speed: 243963 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.2073 | Val Loss: 129.3197\n",
      "Step 34600 | Loss: 144.7251 | LR: 5.27e-05 | Speed: 170346 tok/s\n",
      "Step 34700 | Loss: 132.8342 | LR: 5.22e-05 | Speed: 245569 tok/s\n",
      "Step 34800 | Loss: 128.2150 | LR: 5.17e-05 | Speed: 244510 tok/s\n",
      "Step 34900 | Loss: 137.6717 | LR: 5.11e-05 | Speed: 242065 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_35000.pt\n",
      "Step 35000 | Loss: 143.4452 | LR: 5.06e-05 | Speed: 221412 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.2872 | Val Loss: 127.8845\n",
      "\n",
      "--- Generating ---\n",
      "exture, young the acidity of the wine needing to hold its both sipper, its ripe black fruits that is the fruit to penetrate in t\n",
      "------------------\n",
      "\n",
      "Step 35100 | Loss: 137.7282 | LR: 5.02e-05 | Speed: 163652 tok/s\n",
      "Step 35200 | Loss: 151.7111 | LR: 4.97e-05 | Speed: 247339 tok/s\n",
      "Step 35300 | Loss: 149.7120 | LR: 4.92e-05 | Speed: 243074 tok/s\n",
      "Step 35400 | Loss: 116.9819 | LR: 4.87e-05 | Speed: 239121 tok/s\n",
      "Step 35500 | Loss: 134.8181 | LR: 4.82e-05 | Speed: 235233 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 130.2756 | Val Loss: 127.4423\n",
      "Step 35600 | Loss: 144.7443 | LR: 4.77e-05 | Speed: 175090 tok/s\n",
      "Step 35700 | Loss: 137.7261 | LR: 4.72e-05 | Speed: 243891 tok/s\n",
      "Step 35800 | Loss: 135.2170 | LR: 4.67e-05 | Speed: 242651 tok/s\n",
      "Step 35900 | Loss: 114.3720 | LR: 4.62e-05 | Speed: 246080 tok/s\n",
      "Step 36000 | Loss: 137.6683 | LR: 4.58e-05 | Speed: 243801 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.6732 | Val Loss: 126.0388\n",
      "\n",
      "--- Generating ---\n",
      " has edgy. Perful raw and wiry flavors and fresh fruits ripe, with a moreilike tonch of roasted cola and currants. The one of th\n",
      "------------------\n",
      "\n",
      "Step 36100 | Loss: 126.8090 | LR: 4.53e-05 | Speed: 156818 tok/s\n",
      "Step 36200 | Loss: 123.7594 | LR: 4.48e-05 | Speed: 241681 tok/s\n",
      "Step 36300 | Loss: 123.5561 | LR: 4.44e-05 | Speed: 242660 tok/s\n",
      "Step 36400 | Loss: 117.8819 | LR: 4.39e-05 | Speed: 237816 tok/s\n",
      "Step 36500 | Loss: 153.8407 | LR: 4.34e-05 | Speed: 246761 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 128.9230 | Val Loss: 125.9355\n",
      "Step 36600 | Loss: 137.1264 | LR: 4.30e-05 | Speed: 167644 tok/s\n",
      "Step 36700 | Loss: 138.6727 | LR: 4.25e-05 | Speed: 245343 tok/s\n",
      "Step 36800 | Loss: 131.2469 | LR: 4.20e-05 | Speed: 245590 tok/s\n",
      "Step 36900 | Loss: 139.3032 | LR: 4.16e-05 | Speed: 248991 tok/s\n",
      "Step 37000 | Loss: 137.5464 | LR: 4.11e-05 | Speed: 248020 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 128.3903 | Val Loss: 126.7750\n",
      "\n",
      "--- Generating ---\n",
      "sheroom color. Despite the lotting moment a complex years of, this is overly ripe red. Oaky, candied fruit, with decasting black\n",
      "------------------\n",
      "\n",
      "Step 37100 | Loss: 126.2528 | LR: 4.07e-05 | Speed: 167180 tok/s\n",
      "Step 37200 | Loss: 130.5990 | LR: 4.02e-05 | Speed: 249455 tok/s\n",
      "Step 37300 | Loss: 124.7439 | LR: 3.98e-05 | Speed: 244008 tok/s\n",
      "Step 37400 | Loss: 120.2494 | LR: 3.93e-05 | Speed: 254178 tok/s\n",
      "Step 37500 | Loss: 133.1442 | LR: 3.89e-05 | Speed: 253482 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.1929 | Val Loss: 126.4194\n",
      "Step 37600 | Loss: 131.0711 | LR: 3.85e-05 | Speed: 179335 tok/s\n",
      "Step 37700 | Loss: 121.0956 | LR: 3.80e-05 | Speed: 249393 tok/s\n",
      "Step 37800 | Loss: 128.1772 | LR: 3.76e-05 | Speed: 253424 tok/s\n",
      "Step 37900 | Loss: 121.0397 | LR: 3.72e-05 | Speed: 250044 tok/s\n",
      "Step 38000 | Loss: 114.0385 | LR: 3.68e-05 | Speed: 254599 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.4865 | Val Loss: 127.0049\n",
      "\n",
      "--- Generating ---\n",
      "pcents creat red blackberry pluy modest floral or toasted cotch. This is big wine is fruitined and structured. The red fruit dis\n",
      "------------------\n",
      "\n",
      "Step 38100 | Loss: 140.6422 | LR: 3.63e-05 | Speed: 164841 tok/s\n",
      "Step 38200 | Loss: 118.3034 | LR: 3.59e-05 | Speed: 253060 tok/s\n",
      "Step 38300 | Loss: 136.0024 | LR: 3.55e-05 | Speed: 252683 tok/s\n",
      "Step 38400 | Loss: 104.9484 | LR: 3.51e-05 | Speed: 252411 tok/s\n",
      "Step 38500 | Loss: 136.4695 | LR: 3.47e-05 | Speed: 248442 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 130.1158 | Val Loss: 125.7508\n",
      "Step 38600 | Loss: 117.6732 | LR: 3.43e-05 | Speed: 177241 tok/s\n",
      "Step 38700 | Loss: 121.2775 | LR: 3.39e-05 | Speed: 252415 tok/s\n",
      "Step 38800 | Loss: 136.9228 | LR: 3.35e-05 | Speed: 252884 tok/s\n",
      "Step 38900 | Loss: 134.9791 | LR: 3.31e-05 | Speed: 253202 tok/s\n",
      "Step 39000 | Loss: 139.8270 | LR: 3.27e-05 | Speed: 249495 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.5383 | Val Loss: 126.9660\n",
      "\n",
      "--- Generating ---\n",
      ", and ended with a baked kilchness. Since a rich add some  Casd. Savory, chewy and the balanced finish is entic and pair up with\n",
      "------------------\n",
      "\n",
      "Step 39100 | Loss: 138.2866 | LR: 3.23e-05 | Speed: 165979 tok/s\n",
      "Step 39200 | Loss: 123.8833 | LR: 3.19e-05 | Speed: 253888 tok/s\n",
      "Step 39300 | Loss: 129.3674 | LR: 3.15e-05 | Speed: 248839 tok/s\n",
      "Step 39400 | Loss: 127.3433 | LR: 3.11e-05 | Speed: 247465 tok/s\n",
      "Step 39500 | Loss: 127.4851 | LR: 3.07e-05 | Speed: 249476 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.7194 | Val Loss: 125.7099\n",
      "Step 39600 | Loss: 135.5702 | LR: 3.03e-05 | Speed: 178111 tok/s\n",
      "Step 39700 | Loss: 144.2565 | LR: 3.00e-05 | Speed: 250194 tok/s\n",
      "Step 39800 | Loss: 135.0197 | LR: 2.96e-05 | Speed: 248212 tok/s\n",
      "Step 39900 | Loss: 122.4796 | LR: 2.92e-05 | Speed: 246305 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_40000.pt\n",
      "Step 40000 | Loss: 132.0579 | LR: 2.89e-05 | Speed: 229395 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.3469 | Val Loss: 125.8502\n",
      "\n",
      "--- Generating ---\n",
      "opens withouce of superforeh. Dry but fruity, pineapple jam and ripe flavors, pleasingly with nicely off dry, but there's some r\n",
      "------------------\n",
      "\n",
      "Step 40100 | Loss: 124.9279 | LR: 2.85e-05 | Speed: 162608 tok/s\n",
      "Step 40200 | Loss: 150.1516 | LR: 2.81e-05 | Speed: 253625 tok/s\n",
      "Step 40300 | Loss: 128.6162 | LR: 2.78e-05 | Speed: 253977 tok/s\n",
      "Step 40400 | Loss: 117.9934 | LR: 2.74e-05 | Speed: 243359 tok/s\n",
      "Step 40500 | Loss: 129.6913 | LR: 2.71e-05 | Speed: 255176 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 128.8404 | Val Loss: 125.7155\n",
      "Step 40600 | Loss: 121.8989 | LR: 2.67e-05 | Speed: 181316 tok/s\n",
      "Step 40700 | Loss: 109.2488 | LR: 2.64e-05 | Speed: 246543 tok/s\n",
      "Step 40800 | Loss: 128.8616 | LR: 2.61e-05 | Speed: 254399 tok/s\n",
      "Step 40900 | Loss: 124.6157 | LR: 2.57e-05 | Speed: 243643 tok/s\n",
      "Step 41000 | Loss: 131.9651 | LR: 2.54e-05 | Speed: 244505 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 129.5590 | Val Loss: 125.2591\n",
      "\n",
      "--- Generating ---\n",
      "ar juicy berry fruit on he finish. Loams, mild oary on the nose, this blend is round, and savory, and there's even acid-baked ta\n",
      "------------------\n",
      "\n",
      "Step 41100 | Loss: 122.6811 | LR: 2.51e-05 | Speed: 168488 tok/s\n",
      "Step 41200 | Loss: 141.8633 | LR: 2.47e-05 | Speed: 246764 tok/s\n",
      "Step 41300 | Loss: 138.4076 | LR: 2.44e-05 | Speed: 250519 tok/s\n",
      "Step 41400 | Loss: 116.8415 | LR: 2.41e-05 | Speed: 248635 tok/s\n",
      "Step 41500 | Loss: 113.1478 | LR: 2.38e-05 | Speed: 251389 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.7775 | Val Loss: 124.4111\n",
      "Step 41600 | Loss: 139.0956 | LR: 2.34e-05 | Speed: 176923 tok/s\n",
      "Step 41700 | Loss: 135.5811 | LR: 2.31e-05 | Speed: 252136 tok/s\n",
      "Step 41800 | Loss: 133.8920 | LR: 2.28e-05 | Speed: 256429 tok/s\n",
      "Step 41900 | Loss: 147.5090 | LR: 2.25e-05 | Speed: 252942 tok/s\n",
      "Step 42000 | Loss: 141.5075 | LR: 2.22e-05 | Speed: 254368 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 128.3359 | Val Loss: 124.7263\n",
      "\n",
      "--- Generating ---\n",
      " the tanni tart. Gaod acidity, time still five years to ags. Drink from 2018. This is a necely histericular ronouge blush its fl\n",
      "------------------\n",
      "\n",
      "Step 42100 | Loss: 134.0370 | LR: 2.19e-05 | Speed: 164474 tok/s\n",
      "Step 42200 | Loss: 140.5210 | LR: 2.16e-05 | Speed: 254349 tok/s\n",
      "Step 42300 | Loss: 123.3662 | LR: 2.13e-05 | Speed: 255136 tok/s\n",
      "Step 42400 | Loss: 133.0004 | LR: 2.11e-05 | Speed: 246190 tok/s\n",
      "Step 42500 | Loss: 147.6664 | LR: 2.08e-05 | Speed: 248149 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 125.3524 | Val Loss: 126.0645\n",
      "Step 42600 | Loss: 118.0421 | LR: 2.05e-05 | Speed: 176452 tok/s\n",
      "Step 42700 | Loss: 128.0643 | LR: 2.02e-05 | Speed: 254440 tok/s\n",
      "Step 42800 | Loss: 128.1780 | LR: 1.99e-05 | Speed: 249907 tok/s\n",
      "Step 42900 | Loss: 113.9154 | LR: 1.97e-05 | Speed: 252271 tok/s\n",
      "Step 43000 | Loss: 122.4912 | LR: 1.94e-05 | Speed: 251839 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.7306 | Val Loss: 124.1670\n",
      "\n",
      "--- Generating ---\n",
      "ave suggest onderful less and resin scents the nose. The palate is cool, almost. The soft and plush and fresh, and mishls strawb\n",
      "------------------\n",
      "\n",
      "Step 43100 | Loss: 134.0927 | LR: 1.91e-05 | Speed: 161062 tok/s\n",
      "Step 43200 | Loss: 142.6460 | LR: 1.89e-05 | Speed: 252971 tok/s\n",
      "Step 43300 | Loss: 128.3030 | LR: 1.86e-05 | Speed: 254960 tok/s\n",
      "Step 43400 | Loss: 123.2015 | LR: 1.84e-05 | Speed: 256651 tok/s\n",
      "Step 43500 | Loss: 137.6003 | LR: 1.81e-05 | Speed: 251869 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.1560 | Val Loss: 126.0618\n",
      "Step 43600 | Loss: 125.4979 | LR: 1.79e-05 | Speed: 176409 tok/s\n",
      "Step 43700 | Loss: 130.6039 | LR: 1.76e-05 | Speed: 253250 tok/s\n",
      "Step 43800 | Loss: 113.9115 | LR: 1.74e-05 | Speed: 252783 tok/s\n",
      "Step 43900 | Loss: 135.9869 | LR: 1.72e-05 | Speed: 251797 tok/s\n",
      "Step 44000 | Loss: 124.9038 | LR: 1.69e-05 | Speed: 254026 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 126.9744 | Val Loss: 126.0707\n",
      "\n",
      "--- Generating ---\n",
      " leathery in tangerine prette listed flavors tiepped up. The fruit in juicy ends with tight flate intensity. This is a tannic,ae\n",
      "------------------\n",
      "\n",
      "Step 44100 | Loss: 134.4201 | LR: 1.67e-05 | Speed: 165202 tok/s\n",
      "Step 44200 | Loss: 139.7892 | LR: 1.65e-05 | Speed: 245383 tok/s\n",
      "Step 44300 | Loss: 127.8839 | LR: 1.63e-05 | Speed: 255628 tok/s\n",
      "Step 44400 | Loss: 129.2372 | LR: 1.61e-05 | Speed: 254473 tok/s\n",
      "Step 44500 | Loss: 136.6934 | LR: 1.58e-05 | Speed: 244155 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 125.9880 | Val Loss: 125.2385\n",
      "Step 44600 | Loss: 123.2385 | LR: 1.56e-05 | Speed: 178089 tok/s\n",
      "Step 44700 | Loss: 132.9516 | LR: 1.54e-05 | Speed: 249946 tok/s\n",
      "Step 44800 | Loss: 138.8434 | LR: 1.52e-05 | Speed: 246675 tok/s\n",
      "Step 44900 | Loss: 128.2530 | LR: 1.50e-05 | Speed: 247486 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_45000.pt\n",
      "Step 45000 | Loss: 138.2124 | LR: 1.48e-05 | Speed: 230250 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.2725 | Val Loss: 125.8333\n",
      "\n",
      "--- Generating ---\n",
      "icot, fauits, bubble, matern cigar and mocha. The tannins are nuanced as weeven to now as definition from aging, this is a big, \n",
      "------------------\n",
      "\n",
      "Step 45100 | Loss: 139.3380 | LR: 1.46e-05 | Speed: 169248 tok/s\n",
      "Step 45200 | Loss: 144.3005 | LR: 1.45e-05 | Speed: 254347 tok/s\n",
      "Step 45300 | Loss: 130.9378 | LR: 1.43e-05 | Speed: 253470 tok/s\n",
      "Step 45400 | Loss: 120.8250 | LR: 1.41e-05 | Speed: 252190 tok/s\n",
      "Step 45500 | Loss: 135.1644 | LR: 1.39e-05 | Speed: 246455 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.3687 | Val Loss: 125.5812\n",
      "Step 45600 | Loss: 132.7756 | LR: 1.38e-05 | Speed: 183161 tok/s\n",
      "Step 45700 | Loss: 140.6017 | LR: 1.36e-05 | Speed: 250408 tok/s\n",
      "Step 45800 | Loss: 122.5713 | LR: 1.34e-05 | Speed: 251193 tok/s\n",
      "Step 45900 | Loss: 125.1461 | LR: 1.33e-05 | Speed: 254593 tok/s\n",
      "Step 46000 | Loss: 122.8102 | LR: 1.31e-05 | Speed: 250680 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 126.1262 | Val Loss: 123.9173\n",
      "\n",
      "--- Generating ---\n",
      "structured wine, ripe nuances, but chergieg in efith, tannins, black cherry and juiciness with pipe corn opens plenty of chocola\n",
      "------------------\n",
      "\n",
      "Step 46100 | Loss: 125.9865 | LR: 1.30e-05 | Speed: 166481 tok/s\n",
      "Step 46200 | Loss: 136.3931 | LR: 1.28e-05 | Speed: 251386 tok/s\n",
      "Step 46300 | Loss: 137.8737 | LR: 1.27e-05 | Speed: 254327 tok/s\n",
      "Step 46400 | Loss: 125.5832 | LR: 1.25e-05 | Speed: 254979 tok/s\n",
      "Step 46500 | Loss: 142.4196 | LR: 1.24e-05 | Speed: 251627 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 128.8979 | Val Loss: 126.3661\n",
      "Step 46600 | Loss: 121.9893 | LR: 1.22e-05 | Speed: 182072 tok/s\n",
      "Step 46700 | Loss: 137.5136 | LR: 1.21e-05 | Speed: 251426 tok/s\n",
      "Step 46800 | Loss: 123.1290 | LR: 1.20e-05 | Speed: 256908 tok/s\n",
      "Step 46900 | Loss: 131.3939 | LR: 1.19e-05 | Speed: 250879 tok/s\n",
      "Step 47000 | Loss: 134.5094 | LR: 1.18e-05 | Speed: 254573 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.8176 | Val Loss: 124.8231\n",
      "\n",
      "--- Generating ---\n",
      " fleshy on the nose, and the palate is lime-l on the nose leades in grapefruit flavors of oak but also displaring lemony or aged\n",
      "------------------\n",
      "\n",
      "Step 47100 | Loss: 137.6949 | LR: 1.16e-05 | Speed: 166576 tok/s\n",
      "Step 47200 | Loss: 138.7663 | LR: 1.15e-05 | Speed: 252669 tok/s\n",
      "Step 47300 | Loss: 137.3239 | LR: 1.14e-05 | Speed: 248621 tok/s\n",
      "Step 47400 | Loss: 129.8436 | LR: 1.13e-05 | Speed: 248830 tok/s\n",
      "Step 47500 | Loss: 133.7173 | LR: 1.12e-05 | Speed: 249896 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 125.8407 | Val Loss: 125.3234\n",
      "Step 47600 | Loss: 133.0636 | LR: 1.11e-05 | Speed: 181207 tok/s\n",
      "Step 47700 | Loss: 131.7292 | LR: 1.10e-05 | Speed: 255740 tok/s\n",
      "Step 47800 | Loss: 131.7782 | LR: 1.09e-05 | Speed: 252046 tok/s\n",
      "Step 47900 | Loss: 128.7485 | LR: 1.09e-05 | Speed: 249972 tok/s\n",
      "Step 48000 | Loss: 128.5685 | LR: 1.08e-05 | Speed: 254746 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 127.5213 | Val Loss: 123.4200\n",
      "\n",
      "--- Generating ---\n",
      "greess wine. Racy acidity are opunent. Rose berry and black-fruit flavors makes this soft, power along out the fine tannins. Too\n",
      "------------------\n",
      "\n",
      "Step 48100 | Loss: 112.2404 | LR: 1.07e-05 | Speed: 167778 tok/s\n",
      "Step 48200 | Loss: 148.8094 | LR: 1.06e-05 | Speed: 252382 tok/s\n",
      "Step 48300 | Loss: 133.6406 | LR: 1.06e-05 | Speed: 255432 tok/s\n",
      "Step 48400 | Loss: 121.3536 | LR: 1.05e-05 | Speed: 253409 tok/s\n",
      "Step 48500 | Loss: 144.0834 | LR: 1.04e-05 | Speed: 252678 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 128.8023 | Val Loss: 125.4499\n",
      "Step 48600 | Loss: 129.1915 | LR: 1.04e-05 | Speed: 175958 tok/s\n",
      "Step 48700 | Loss: 126.6237 | LR: 1.03e-05 | Speed: 254610 tok/s\n",
      "Step 48800 | Loss: 135.7185 | LR: 1.03e-05 | Speed: 256846 tok/s\n",
      "Step 48900 | Loss: 141.5220 | LR: 1.02e-05 | Speed: 251522 tok/s\n",
      "Step 49000 | Loss: 123.0334 | LR: 1.02e-05 | Speed: 253801 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 125.4636 | Val Loss: 124.3588\n",
      "\n",
      "--- Generating ---\n",
      "lemboy's much price Piorce the nose of cutes. Tobacco and smoke, spine line anilla red from a creamy note that's candy. This is \n",
      "------------------\n",
      "\n",
      "Step 49100 | Loss: 142.4756 | LR: 1.02e-05 | Speed: 166285 tok/s\n",
      "Step 49200 | Loss: 126.3067 | LR: 1.01e-05 | Speed: 256542 tok/s\n",
      "Step 49300 | Loss: 127.2104 | LR: 1.01e-05 | Speed: 253371 tok/s\n",
      "Step 49400 | Loss: 127.6281 | LR: 1.01e-05 | Speed: 252280 tok/s\n",
      "Step 49500 | Loss: 131.5106 | LR: 1.00e-05 | Speed: 251460 tok/s\n",
      "-> Evaluating...\n",
      "-> Train Loss: 126.5494 | Val Loss: 124.9911\n",
      "Step 49600 | Loss: 126.3214 | LR: 1.00e-05 | Speed: 179851 tok/s\n",
      "Step 49700 | Loss: 124.4143 | LR: 1.00e-05 | Speed: 256421 tok/s\n",
      "Step 49800 | Loss: 125.1182 | LR: 1.00e-05 | Speed: 248096 tok/s\n",
      "Step 49900 | Loss: 125.1682 | LR: 1.00e-05 | Speed: 254948 tok/s\n",
      "✓ Checkpoint saved: checkpoints/model_step_50000.pt\n",
      "Training Complete. Total time: 3655.0s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "start_time = time.time() \n",
    "for step in range(start_step, config.max_steps): \n",
    "    \n",
    "    lr = get_lr(step)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr    \n",
    "    xb = get_batch('train', seqlen=config.block_size, batch_size=config.batch_size)\n",
    "    \n",
    "    # Forward & Backward\n",
    "    with torch.amp.autocast(device_type=\"cuda\", dtype=dtype):\n",
    "        loss = model.compute_loss(xb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    if dtype == torch.float16:\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    if step % 100 == 0:\n",
    "        torch.cuda.synchronize() \n",
    "        t1 = time.time()\n",
    "        dt = t1 - t0\n",
    "        t0 = t1\n",
    "        tokens_processed = config.batch_size * config.block_size * 100\n",
    "        tps = tokens_processed / dt\n",
    "        print(f\"Step {step:4d} | Loss: {loss.item():.4f} | LR: {lr:.2e} | Speed: {tps:.0f} tok/s\")\n",
    "    if step % 500 == 0:\n",
    "        print(\"-> Evaluating...\")\n",
    "        losses = estimate_loss()\n",
    "        print(f\"-> Train Loss: {losses['train']:.4f} | Val Loss: {losses['val']:.4f}\")\n",
    "    if step % 1000 == 0:\n",
    "        print(\"\\n--- Generating ---\")\n",
    "        gen_ids = model.generate(seq_len=config.block_size, steps=64)\n",
    "        print(decode(gen_ids))\n",
    "        print(\"------------------\\n\")\n",
    "    \n",
    "    # Checkpoint\n",
    "    if (step+1) % 5000 == 0:\n",
    "        checkpoint_path = f\"checkpoints/model_step_{(step+1)}.pt\"\n",
    "        torch.save({\n",
    "            'step': (step+1),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'config': config,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"✓ Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training Complete. Total time: {total_time:.1f}s\")\n",
    "# -> 50k*128*128 =  819M tokens training\n",
    "# -> roughly 1h @ 250kT/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223648a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoints...\n",
      "\n",
      "    Step | Train Loss |   Val Loss\n",
      "-----------------------------------\n",
      "    5000 |   163.6587 |   161.5879\n",
      "   10000 |   150.1948 |   149.5160\n",
      "   15000 |   142.9646 |   139.1608\n",
      "   20000 |   139.6942 |   136.4029\n",
      "   25000 |   135.2363 |   132.2800\n",
      "   30000 |   132.3328 |   130.1084\n",
      "   35000 |   129.8577 |   128.3031\n",
      "   40000 |   128.3549 |   126.6261\n",
      "   45000 |   126.1109 |   125.4059\n",
      "   50000 |   125.6819 |   125.6412\n"
     ]
    }
   ],
   "source": [
    "# Print all checkpoints to see their train / test loss error\n",
    "# 'What's the overfitting situation?'\n",
    "\n",
    "import glob\n",
    "import re\n",
    "model.eval()\n",
    "# Find all checkpoint files\n",
    "checkpoint_files = sorted(glob.glob('checkpoints/model_step_*.pt'))\n",
    "# Extract step numbers and sort\n",
    "checkpoint_files = sorted(checkpoint_files, key=lambda x: int(re.search(r'step_(\\d+)', x).group(1)))\n",
    "print(\"Evaluating checkpoints...\\n\")\n",
    "print(f\"{'Step':>8} | {'Train Loss':>10} | {'Val Loss':>10}\")\n",
    "print(\"-\" * 35)\n",
    "for checkpoint_path in checkpoint_files:\n",
    "    # Extract step number from filename\n",
    "    step_num = int(re.search(r'step_(\\d+)', checkpoint_path).group(1))\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    losses = estimate_loss(eval_iters=50)\n",
    "    print(f\"{step_num:8d} | {losses['train']:10.4f} | {losses['val']:10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b56f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Saving Model Bundle ---\n",
      "Saved blobs/my_model_weights.pt.part000 (25.00 MB)\n",
      "Saved blobs/my_model_weights.pt.part001 (25.00 MB)\n",
      "Saved blobs/my_model_weights.pt.part002 (25.00 MB)\n",
      "Saved blobs/my_model_weights.pt.part003 (25.00 MB)\n",
      "Saved blobs/my_model_weights.pt.part004 (25.00 MB)\n",
      "Saved blobs/my_model_weights.pt.part005 (25.00 MB)\n",
      "Saved blobs/my_model_weights.pt.part006 (4.99 MB)\n",
      "\n",
      "--- Saving Optimizer Bundle ---\n",
      "Saved blobs/my_optimizer_state.pt.part000 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part001 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part002 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part003 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part004 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part005 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part006 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part007 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part008 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part009 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part010 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part011 (25.00 MB)\n",
      "Saved blobs/my_optimizer_state.pt.part012 (9.98 MB)\n"
     ]
    }
   ],
   "source": [
    "# Load once more and save it in 25MB blobs so that Github accepts it #\n",
    "\n",
    "\n",
    "CHUNK_SIZE_LIMIT = 25 * 1024 * 1024 # MB per blob\n",
    "\n",
    "import io\n",
    "def save_chunked(obj, file_prefix, chunk_size=CHUNK_SIZE_LIMIT):\n",
    "    \"\"\"\n",
    "    Serializes a python/torch object and saves it in parts \n",
    "    no larger than chunk_size.\n",
    "    \"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(obj, buffer)\n",
    "    buffer.seek(0)\n",
    "    part_num = 0\n",
    "    while True:\n",
    "        chunk = buffer.read(chunk_size)\n",
    "        if not chunk:\n",
    "            break\n",
    "        # filenames like: model_weights.pt.part000, model_weights.pt.part001\n",
    "        filename = f\"blobs/{file_prefix}.part{part_num:03d}\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(chunk)\n",
    "        print(f\"Saved {filename} ({len(chunk) / 1024 / 1024:.2f} MB)\")\n",
    "        part_num += 1\n",
    "\n",
    "# Load checkpoint once more and save it directly after\n",
    "checkpoint = torch.load('checkpoints/model_step_50000.pt', map_location=\"cpu\", weights_only=False)\n",
    "# Model Dictionary (Weights + Metadata)\n",
    "model_bundle = {\n",
    "    'step': checkpoint['step'],\n",
    "    'loss': checkpoint['loss'],\n",
    "    'config': checkpoint['config'],\n",
    "    'model_state_dict': checkpoint['model_state_dict'] \n",
    "}\n",
    "# Optimizer Dictionary\n",
    "optimizer_bundle = {\n",
    "    'optimizer_state_dict': checkpoint['optimizer_state_dict']\n",
    "}\n",
    "print(\"--- Saving Model Bundle ---\")\n",
    "save_chunked(model_bundle, \"my_model_weights.pt\")\n",
    "print(\"\\n--- Saving Optimizer Bundle ---\")\n",
    "save_chunked(optimizer_bundle, \"my_optimizer_state.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
